# pyspark

- round() -> .cast('integer')
- nunique() -> .countDistinct()
- calculate column -> .withColumn('', col('')...)
- change column name -> .alias()
